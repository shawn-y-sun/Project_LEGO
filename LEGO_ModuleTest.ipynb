{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project LEGO - Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from Technic.data import DataManager\n",
    "from Technic.feature import Interaction\n",
    "from Technic.condition import create_conditional_var\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data manager (assuming it's already initialized)\n",
    "# dm = DataManager(...)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Examples of Creating Interaction Terms\n",
    "\n",
    "The `Interaction` class provides various ways to create interaction terms between variables. Here are some common use cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple Multiplication Interaction\n",
    "gdp_unemp = Interaction(\n",
    "    vars=['GDP', 'UNRATE'],\n",
    "    interaction_type='multiply'  # default type\n",
    ")\n",
    "\n",
    "# 2. Ratio Interaction with Lag\n",
    "gdp_lag_unemp = Interaction(\n",
    "    vars=['GDP', 'UNRATE'],\n",
    "    interaction_type='ratio',  # uses safe division (adds small constant to denominator)\n",
    "    lag=1  # lags UNRATE by 1 period\n",
    ")\n",
    "\n",
    "# 3. Polynomial Interaction (GDP² * UNRATE)\n",
    "gdp_sq_unemp = Interaction(\n",
    "    vars=['GDP', 'UNRATE'],\n",
    "    interaction_type='polynomial',\n",
    "    powers=[2, 1]  # GDP squared, UNRATE linear\n",
    ")\n",
    "\n",
    "# 4. Multiple Variable Interaction\n",
    "gdp_unemp_cpi = Interaction(\n",
    "    vars=['GDP', 'UNRATE', 'CPI'],\n",
    "    interaction_type='multiply'\n",
    ")\n",
    "\n",
    "# Use these in feature building\n",
    "features = dm.build_features([\n",
    "    'GDP',\n",
    "    'UNRATE',\n",
    "    gdp_unemp,          # GDP * UNRATE\n",
    "    gdp_lag_unemp,      # GDP / UNRATE(t-1)\n",
    "    gdp_sq_unemp,       # GDP² * UNRATE\n",
    "    gdp_unemp_cpi       # GDP * UNRATE * CPI\n",
    "])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Examples of Creating Conditional Variables\n",
    "\n",
    "The `create_conditional_var` function provides an easy way to create conditional variables. Here are some common use cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. High Unemployment Regime (UNRATE > 10%)\n",
    "def high_unemp(series):\n",
    "    \"\"\"When unemployment > 10%, use the rate; otherwise 0\"\"\"\n",
    "    return series.where(series > 0.10, other=0)\n",
    "\n",
    "create_conditional_var(\n",
    "    dm,\n",
    "    main_var='UNRATE',\n",
    "    condition=high_unemp,\n",
    "    alias='UNEMP_REGIME'\n",
    ")\n",
    "\n",
    "# 2. GDP in Recession (negative growth)\n",
    "def recession_gdp(series):\n",
    "    \"\"\"When GDP growth is negative, use GDP; otherwise 0\"\"\"\n",
    "    return series.where(series.pct_change() < 0, other=0)\n",
    "\n",
    "create_conditional_var(\n",
    "    dm,\n",
    "    main_var='GDP',\n",
    "    condition=recession_gdp,\n",
    "    alias='GDP_RECESSION'\n",
    ")\n",
    "\n",
    "# 3. Conditional on Another Variable\n",
    "def gdp_in_high_unemp(series, unrate):\n",
    "    \"\"\"GDP values during high unemployment periods\"\"\"\n",
    "    return series.where(unrate > 0.10, other=0)\n",
    "\n",
    "create_conditional_var(\n",
    "    dm,\n",
    "    main_var='GDP',\n",
    "    # Use lambda to access other variables\n",
    "    condition=lambda x: gdp_in_high_unemp(x, dm.model_mev['UNRATE']),\n",
    "    alias='GDP_HIGH_UNEMP'\n",
    ")\n",
    "\n",
    "# 4. Multiple Conditions\n",
    "def stagflation(series, gdp, cpi):\n",
    "    \"\"\"\n",
    "    Unemployment during stagflation periods:\n",
    "    - GDP growth < 1%\n",
    "    - Inflation (CPI) > 5%\n",
    "    \"\"\"\n",
    "    gdp_growth = gdp.pct_change()\n",
    "    cpi_growth = cpi.pct_change()\n",
    "    stagflation_mask = (gdp_growth < 0.01) & (cpi_growth > 0.05)\n",
    "    return series.where(stagflation_mask, other=0)\n",
    "\n",
    "create_conditional_var(\n",
    "    dm,\n",
    "    main_var='UNRATE',\n",
    "    condition=lambda x: stagflation(\n",
    "        x, \n",
    "        dm.model_mev['GDP'],\n",
    "        dm.model_mev['CPI']\n",
    "    ),\n",
    "    alias='UNEMP_STAGFLATION'\n",
    ")\n",
    "\n",
    "# 5. Return Series without Adding to Data\n",
    "def extreme_values(series):\n",
    "    \"\"\"Identify extreme values (>2 std from mean)\"\"\"\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    return series.where((series > mean + 2*std) | (series < mean - 2*std), other=0)\n",
    "\n",
    "extreme_gdp = create_conditional_var(\n",
    "    dm,\n",
    "    main_var='GDP',\n",
    "    condition=extreme_values,\n",
    "    alias='GDP_EXTREME',\n",
    "    add_to_data=False  # Don't add to datasets, just return the series\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Verifying the Results\n",
    "\n",
    "Let's check some of our created variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check interaction terms\n",
    "print(\"=== Interaction Terms ===\")\n",
    "print(\"\\nGDP * UNRATE:\")\n",
    "print(features[['GDP', 'UNRATE', 'GDP_UNRATE_MUL']].head())\n",
    "\n",
    "print(\"\\nGDP / UNRATE(t-1):\")\n",
    "print(features[['GDP', 'UNRATE', 'GDP_UNRATE_RATIO_LAG1']].head())\n",
    "\n",
    "print(\"\\nGDP² * UNRATE:\")\n",
    "print(features[['GDP', 'UNRATE', 'GDP_UNRATE_POW2,1']].head())\n",
    "\n",
    "# Check conditional variables\n",
    "print(\"\\n=== Conditional Variables ===\")\n",
    "print(\"\\nHigh Unemployment Regime:\")\n",
    "print(dm.model_mev[['UNRATE', 'UNEMP_REGIME']].head())\n",
    "\n",
    "print(\"\\nGDP during High Unemployment:\")\n",
    "print(dm.model_mev[['GDP', 'UNRATE', 'GDP_HIGH_UNEMP']].head())\n",
    "\n",
    "print(\"\\nUnemployment during Stagflation:\")\n",
    "print(dm.model_mev[['UNRATE', 'GDP', 'CPI', 'UNEMP_STAGFLATION']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Package and Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Technic as tc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "            Fixed_balance  Fixed_price  Redeemable_balance  Redeemable_price  \\\n",
      "Date                                                                           \n",
      "2018-01-31    1525.766256     0.054260          808.925168          0.018648   \n",
      "2018-02-28    1540.515474     0.046348          835.771506          0.034777   \n",
      "2018-03-31    1566.467979     0.026517          863.370334          0.017302   \n",
      "2018-04-30    1563.129764     0.022823          896.188563          0.036981   \n",
      "2018-05-31    1583.883081     0.045697          908.819056          0.032661   \n",
      "\n",
      "             VR_balance  VR_price  \n",
      "Date                               \n",
      "2018-01-31  1022.483571  0.045600  \n",
      "2018-02-28  1041.792249  0.023520  \n",
      "2018-03-31  1065.030692  0.025023  \n",
      "2018-04-30  1092.645841  0.013759  \n",
      "2018-05-31  1111.475074  0.033131  \n"
     ]
    }
   ],
   "source": [
    "# create DataLoader\n",
    "data_ldr = tc.PPNRInternalLoader()\n",
    "\n",
    "# Load data with proper parameters\n",
    "data_ldr.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'  # Specify the date column name from your Excel\n",
    ")\n",
    "\n",
    "# Print first few rows to verify\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data_ldr.internal_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Test Different Features of PPNRInternalLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 1. Test Sample Splitting with Time Cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample period data:\n",
      "Start: 2018-01-31 00:00:00\n",
      "End: 2019-06-30 00:00:00\n",
      "Number of observations: 18\n",
      "\n",
      "Out-of-sample period data:\n",
      "Start: 2019-07-31 00:00:00\n",
      "End: 2023-11-30 00:00:00\n",
      "Number of observations: 53\n"
     ]
    }
   ],
   "source": [
    "# Create loader with in-sample period specified\n",
    "data_ldr_split = tc.PPNRInternalLoader(\n",
    "    in_sample_start=\"2018-01-01\",\n",
    "    in_sample_end=\"2019-06-30\"\n",
    ")\n",
    "\n",
    "# Load the same data\n",
    "data_ldr_split.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Get in-sample and out-of-sample data\n",
    "in_sample_data = data_ldr_split.internal_data.loc[data_ldr_split.in_sample_idx]\n",
    "out_sample_data = data_ldr_split.internal_data.loc[data_ldr_split.out_sample_idx]\n",
    "\n",
    "print(\"In-sample period data:\")\n",
    "print(f\"Start: {in_sample_data.index.min()}\")\n",
    "print(f\"End: {in_sample_data.index.max()}\")\n",
    "print(f\"Number of observations: {len(in_sample_data)}\\n\")\n",
    "\n",
    "print(\"Out-of-sample period data:\")\n",
    "print(f\"Start: {out_sample_data.index.min()}\")\n",
    "print(f\"End: {out_sample_data.index.max()}\")\n",
    "print(f\"Number of observations: {len(out_sample_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 2. Test Different Frequency Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly frequency data (original):\n",
      "            Fixed_balance  Fixed_price  Redeemable_balance  Redeemable_price  \\\n",
      "Date                                                                           \n",
      "2018-01-31    1525.766256     0.054260          808.925168          0.018648   \n",
      "2018-02-28    1540.515474     0.046348          835.771506          0.034777   \n",
      "2018-03-31    1566.467979     0.026517          863.370334          0.017302   \n",
      "2018-04-30    1563.129764     0.022823          896.188563          0.036981   \n",
      "2018-05-31    1583.883081     0.045697          908.819056          0.032661   \n",
      "\n",
      "             VR_balance  VR_price  \n",
      "Date                               \n",
      "2018-01-31  1022.483571  0.045600  \n",
      "2018-02-28  1041.792249  0.023520  \n",
      "2018-03-31  1065.030692  0.025023  \n",
      "2018-04-30  1092.645841  0.013759  \n",
      "2018-05-31  1111.475074  0.033131   \n",
      "\n",
      "Quarterly frequency data (converted):\n",
      "            Fixed_balance  Fixed_price  Redeemable_balance  Redeemable_price  \\\n",
      "Date                                                                           \n",
      "2018-03-31    1525.766256     0.054260          808.925168          0.018648   \n",
      "2018-03-31    1540.515474     0.046348          835.771506          0.034777   \n",
      "2018-03-31    1566.467979     0.026517          863.370334          0.017302   \n",
      "2018-06-30    1563.129764     0.022823          896.188563          0.036981   \n",
      "2018-06-30    1583.883081     0.045697          908.819056          0.032661   \n",
      "\n",
      "             VR_balance  VR_price  \n",
      "Date                               \n",
      "2018-03-31  1022.483571  0.045600  \n",
      "2018-03-31  1041.792249  0.023520  \n",
      "2018-03-31  1065.030692  0.025023  \n",
      "2018-06-30  1092.645841  0.013759  \n",
      "2018-06-30  1111.475074  0.033131  \n"
     ]
    }
   ],
   "source": [
    "# Create loader with quarterly frequency\n",
    "data_ldr_q = tc.PPNRInternalLoader(freq='Q')\n",
    "\n",
    "# Load the same data - it will be automatically converted to quarter-end dates\n",
    "data_ldr_q.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Compare the first few rows of monthly vs quarterly data\n",
    "print(\"Monthly frequency data (original):\")\n",
    "print(data_ldr.internal_data.head(), \"\\n\")\n",
    "\n",
    "print(\"Quarterly frequency data (converted):\")\n",
    "print(data_ldr_q.internal_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 3. Test Full Sample Period Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data range with constraints:\n",
      "Start: 2018-01-31 00:00:00\n",
      "End: 2023-11-30 00:00:00\n",
      "\n",
      "In-sample period:\n",
      "Start: 2018-06-30 00:00:00\n",
      "End: 2019-06-30 00:00:00\n",
      "\n",
      "Out-of-sample period:\n",
      "Start: 2019-07-31 00:00:00\n",
      "End: 2019-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create loader with full sample period constraints\n",
    "data_ldr_constrained = tc.PPNRInternalLoader(\n",
    "    in_sample_start=\"2018-06-01\",\n",
    "    in_sample_end=\"2019-06-30\",\n",
    "    full_sample_start=\"2018-03-01\",  # Start a bit later\n",
    "    full_sample_end=\"2019-12-31\"     # End a bit earlier\n",
    ")\n",
    "\n",
    "# Load the data\n",
    "data_ldr_constrained.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Show the data ranges\n",
    "full_data = data_ldr_constrained.internal_data\n",
    "in_sample = full_data.loc[data_ldr_constrained.in_sample_idx]\n",
    "out_sample = full_data.loc[data_ldr_constrained.out_sample_idx]\n",
    "\n",
    "print(\"Full data range with constraints:\")\n",
    "print(f\"Start: {full_data.index.min()}\")\n",
    "print(f\"End: {full_data.index.max()}\\n\")\n",
    "\n",
    "print(\"In-sample period:\")\n",
    "print(f\"Start: {in_sample.index.min()}\")\n",
    "print(f\"End: {in_sample.index.max()}\\n\")\n",
    "\n",
    "print(\"Out-of-sample period:\")\n",
    "print(f\"Start: {out_sample.index.min()}\")\n",
    "print(f\"End: {out_sample.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 4. Test Loading from DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from DataFrame:\n",
      "                  Value\n",
      "Date                   \n",
      "2018-01-31  1112.698711\n",
      "2018-02-28  1079.304995\n",
      "2018-03-31   926.166426\n",
      "2018-04-30   812.336866\n",
      "2018-05-31   857.927135\n",
      "\n",
      "Index properties:\n",
      "Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "Frequency: M\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range(start='2018-01-01', end='2019-12-31', freq='M')\n",
    "sample_df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Value': np.random.randn(len(dates)) * 100 + 1000\n",
    "})\n",
    "\n",
    "# Create loader and load from DataFrame\n",
    "data_ldr_df = tc.PPNRInternalLoader()\n",
    "data_ldr_df.load(\n",
    "    source=sample_df,\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "print(\"Data loaded from DataFrame:\")\n",
    "print(data_ldr_df.internal_data.head())\n",
    "\n",
    "# Verify the index is properly set\n",
    "print(\"\\nIndex properties:\")\n",
    "print(f\"Index type: {type(data_ldr_df.internal_data.index)}\")\n",
    "print(f\"Frequency: {data_ldr_df.internal_data.index.freqstr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 5. Test Loading Without date_col Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: DataFrame with DatetimeIndex\n",
      "----------------------------------------\n",
      "Original DataFrame with DatetimeIndex:\n",
      "                 Value1      Value2\n",
      "2018-01-31  1183.977935  512.167354\n",
      "2018-02-28   858.603155  563.516392\n",
      "2018-03-31  1082.256032  560.291478\n",
      "2018-04-30  1302.497407  578.676383\n",
      "2018-05-31  1137.632037  456.047272 \n",
      "\n",
      "Loaded data (should preserve the index):\n",
      "                 Value1      Value2\n",
      "2018-01-31  1183.977935  512.167354\n",
      "2018-02-28   858.603155  563.516392\n",
      "2018-03-31  1082.256032  560.291478\n",
      "2018-04-30  1302.497407  578.676383\n",
      "2018-05-31  1137.632037  456.047272 \n",
      "\n",
      "Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "Frequency: M\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: DataFrame with DatetimeIndex\n",
    "print(\"Test Case 1: DataFrame with DatetimeIndex\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a DataFrame with DatetimeIndex\n",
    "dates_index = pd.date_range(start='2018-01-01', end='2019-12-31', freq='M')\n",
    "df_with_index = pd.DataFrame({\n",
    "    'Value1': np.random.randn(len(dates_index)) * 100 + 1000,\n",
    "    'Value2': np.random.randn(len(dates_index)) * 50 + 500\n",
    "}, index=dates_index)\n",
    "\n",
    "print(\"Original DataFrame with DatetimeIndex:\")\n",
    "print(df_with_index.head(), \"\\n\")\n",
    "\n",
    "# Load without specifying date_col\n",
    "data_ldr_indexed = tc.PPNRInternalLoader()\n",
    "data_ldr_indexed.load(source=df_with_index)\n",
    "\n",
    "print(\"Loaded data (should preserve the index):\")\n",
    "print(data_ldr_indexed.internal_data.head(), \"\\n\")\n",
    "print(f\"Index type: {type(data_ldr_indexed.internal_data.index)}\")\n",
    "print(f\"Frequency: {data_ldr_indexed.internal_data.index.freqstr}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 2: DataFrame without DatetimeIndex\n",
      "----------------------------------------\n",
      "Original DataFrame without DatetimeIndex:\n",
      "        Date       Value1      Value2\n",
      "0 2018-01-31   997.955475  498.654784\n",
      "1 2018-02-28   999.515419  571.159186\n",
      "2 2018-03-31   937.649897  399.392914\n",
      "3 2018-04-30  1071.443102  495.720292\n",
      "4 2018-05-31  1132.465135  491.003424 \n",
      "\n",
      "Expected error raised:\n",
      "date_col required when DataFrame does not have datetime index\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: DataFrame without DatetimeIndex\n",
    "print(\"Test Case 2: DataFrame without DatetimeIndex\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a DataFrame without DatetimeIndex (regular numeric index)\n",
    "df_without_index = pd.DataFrame({\n",
    "    'Date': dates_index,  # Date as a column instead of index\n",
    "    'Value1': np.random.randn(len(dates_index)) * 100 + 1000,\n",
    "    'Value2': np.random.randn(len(dates_index)) * 50 + 500\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame without DatetimeIndex:\")\n",
    "print(df_without_index.head(), \"\\n\")\n",
    "\n",
    "# Try to load without specifying date_col (should raise an error)\n",
    "data_ldr_no_index = tc.PPNRInternalLoader()\n",
    "try:\n",
    "    data_ldr_no_index.load(source=df_without_index)\n",
    "    print(\"Loaded data (shouldn't reach here):\")\n",
    "    print(data_ldr_no_index.internal_data.head())\n",
    "except ValueError as e:\n",
    "    print(\"Expected error raised:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Test MEVLoader Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading base MEVs...\n",
      "\n",
      "Quarterly base MEVs:\n",
      "nan           NGDP       PSR      PDI UNRATE   CPI\n",
      "2000-03-31  100.16  10032.57  8047.46   3.64  3.08\n",
      "2000-06-30   99.74   9996.18  8044.02   4.42  3.96\n",
      "2000-09-30   99.77   9940.38  8035.14   4.82   9.3\n",
      "2000-12-31   99.54  10063.83  7958.35   6.23  9.12\n",
      "2001-03-31    99.8   9925.75  8018.19   5.85  7.18\n",
      "\n",
      "MEV codes and their types:\n",
      "CPI: rate - Consumer Price Index\n",
      "NGDP: level - Nominal GDP\n",
      "PDI: level - Personal Disposable Income\n",
      "PSR: rate - Personal Savings Rate\n",
      "UNRATE: rate - Unemployment Rate\n"
     ]
    }
   ],
   "source": [
    "# Create MEVLoader instance\n",
    "mev_ldr = tc.MEVLoader()\n",
    "\n",
    "# Load base MEVs from the 'base' sheet\n",
    "print(\"1. Loading base MEVs...\")\n",
    "mev_ldr.load(\n",
    "    source='fake_scens.xlsx',\n",
    "    sheet='base'\n",
    ")\n",
    "\n",
    "print(\"\\nQuarterly base MEVs:\")\n",
    "print(mev_ldr.model_mev_qtr.head())\n",
    "\n",
    "# Check MEV codes and their types\n",
    "print(\"\\nMEV codes and their types:\")\n",
    "for code in mev_ldr.mev_codes:\n",
    "    info = mev_ldr.get_mev_info(code)\n",
    "    print(f\"{code}: {info['type']} - {info['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading scenario MEVs...\n",
      "\n",
      "Available scenario sets: ['EWST2024']\n",
      "\n",
      "Scenarios in EWST2024: ['Base', 'Adverse', 'Severe']\n",
      "\n",
      "Comparing NGDP across scenarios:\n",
      "\n",
      "Base scenario:\n",
      "2000-03-31    100.16\n",
      "2000-06-30     99.74\n",
      "2000-09-30     99.77\n",
      "2000-12-31     99.54\n",
      "2001-03-31      99.8\n",
      "Freq: Q-DEC, Name: NGDP, dtype: object\n",
      "\n",
      "Adverse scenario:\n",
      "2000-03-31    110.17\n",
      "2000-06-30    109.71\n",
      "2000-09-30    109.74\n",
      "2000-12-31     109.5\n",
      "2001-03-31    109.78\n",
      "Freq: Q-DEC, Name: NGDP, dtype: object\n",
      "\n",
      "Severe scenario:\n",
      "2000-03-31    120.19\n",
      "2000-06-30    119.69\n",
      "2000-09-30    119.72\n",
      "2000-12-31    119.45\n",
      "2001-03-31    119.76\n",
      "Freq: Q-DEC, Name: NGDP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load scenario MEVs from 'adv' and 'sev' sheets\n",
    "print(\"2. Loading scenario MEVs...\")\n",
    "mev_ldr.load_scens(\n",
    "    source='fake_scens.xlsx',\n",
    "    scens={\n",
    "        'Base': 'base',\n",
    "        'Adverse': 'adv',\n",
    "        'Severe': 'sev'\n",
    "    },\n",
    "    set_name='EWST2024'\n",
    ")\n",
    "\n",
    "# Print available scenario sets\n",
    "print(\"\\nAvailable scenario sets:\", list(mev_ldr.scen_mev_qtr.keys()))\n",
    "\n",
    "# Print scenarios in EWST2024\n",
    "print(\"\\nScenarios in EWST2024:\", list(mev_ldr.scen_mev_qtr['EWST2024'].keys()))\n",
    "\n",
    "# Compare scenarios for a specific MEV (e.g., NGDP)\n",
    "print(\"\\nComparing NGDP across scenarios:\")\n",
    "for scen_name, scen_data in mev_ldr.scen_mev_qtr['EWST2024'].items():\n",
    "    print(f\"\\n{scen_name} scenario:\")\n",
    "    print(scen_data['NGDP'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Testing scenario updates...\n",
      "\n",
      "NGDP in Base scenario after update:\n",
      "2000-03-31    101.0\n",
      "2000-06-30    102.0\n",
      "2000-09-30    103.0\n",
      "2000-12-31    104.0\n",
      "2001-03-31    105.0\n",
      "Freq: Q-DEC, Name: NGDP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Test updating scenario MEVs\n",
    "print(\"3. Testing scenario updates...\")\n",
    "\n",
    "# Create a sample update for NGDP in Base scenario\n",
    "import numpy as np\n",
    "\n",
    "# Get existing dates from Base scenario\n",
    "base_dates = mev_ldr.scen_mev_qtr['EWST2024']['Base'].index[:5]\n",
    "updated_values = np.array([101.0, 102.0, 103.0, 104.0, 105.0])\n",
    "\n",
    "update_df = pd.DataFrame({\n",
    "    'NGDP': updated_values\n",
    "}, index=base_dates)\n",
    "\n",
    "# Update the Base scenario\n",
    "mev_ldr.update_scen_mevs(\n",
    "    {'Base': update_df},\n",
    "    set_name='EWST2024'\n",
    ")\n",
    "\n",
    "print(\"\\nNGDP in Base scenario after update:\")\n",
    "print(mev_ldr.scen_mev_qtr['EWST2024']['Base']['NGDP'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Testing cleaning operations...\n",
      "\n",
      "Cleaning EWST2024 scenario set...\n",
      "Scenario sets after cleaning EWST2024: []\n",
      "\n",
      "Cleaning model MEVs...\n",
      "Model MEV shape after cleaning: (0, 0)\n",
      "\n",
      "Cleaning all data...\n",
      "MEV codes after cleaning: []\n",
      "Scenario sets after cleaning: []\n"
     ]
    }
   ],
   "source": [
    "# Test cleaning operations\n",
    "print(\"4. Testing cleaning operations...\")\n",
    "\n",
    "# Clean specific scenario set\n",
    "print(\"\\nCleaning EWST2024 scenario set...\")\n",
    "mev_ldr.clean_scen_mevs(set_name='EWST2024')\n",
    "print(\"Scenario sets after cleaning EWST2024:\", list(mev_ldr.scen_mev_qtr.keys()))\n",
    "\n",
    "# Clean model MEVs\n",
    "print(\"\\nCleaning model MEVs...\")\n",
    "mev_ldr.clean_model_mevs()\n",
    "print(\"Model MEV shape after cleaning:\", mev_ldr.model_mev_qtr.shape)\n",
    "\n",
    "# Clean everything\n",
    "print(\"\\nCleaning all data...\")\n",
    "mev_ldr.clean_all()\n",
    "print(\"MEV codes after cleaning:\", mev_ldr.mev_codes)\n",
    "print(\"Scenario sets after cleaning:\", list(mev_ldr.scen_mev_qtr.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Testing transform mappings...\n",
      "\n",
      "Available transforms by MEV type:\n",
      "level: ['LV', 'GR']\n",
      "rate: ['LV', 'DF', 'GR']\n",
      "\n",
      "Transform types for specific MEVs:\n",
      "NGDP (level): ['LV', 'GR']\n",
      "UNRATE (rate): ['LV', 'DF', 'GR']\n",
      "CPI (rate): ['LV', 'DF', 'GR']\n"
     ]
    }
   ],
   "source": [
    "# Test transform mappings\n",
    "print(\"5. Testing transform mappings...\")\n",
    "\n",
    "# Print available transforms for each MEV type\n",
    "print(\"\\nAvailable transforms by MEV type:\")\n",
    "for mev_type, transforms in mev_ldr.tsfm_map.items():\n",
    "    print(f\"{mev_type}: {transforms}\")\n",
    "\n",
    "# Print transform types for specific MEVs\n",
    "print(\"\\nTransform types for specific MEVs:\")\n",
    "test_mevs = ['NGDP', 'UNRATE', 'CPI']\n",
    "for mev in test_mevs:\n",
    "    mev_type = mev_ldr.get_mev_info(mev)['type']\n",
    "    transforms = mev_ldr.tsfm_map.get(mev_type, [])\n",
    "    print(f\"{mev} ({mev_type}): {transforms}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DataManager Class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Test DataManager Initialization and Basic Data Access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Data Shape: (71, 6)\n",
      "Internal Data Columns: ['Fixed_balance', 'Fixed_price', 'Redeemable_balance', 'Redeemable_price', 'VR_balance', 'VR_price']\n",
      "\n",
      "In-Sample Data Range:\n",
      "Start: 2018-01-31 00:00:00\n",
      "End: 2019-06-30 00:00:00\n",
      "\n",
      "Out-Sample Data Range:\n",
      "Start: 2019-07-31 00:00:00\n",
      "End: 2023-11-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create and load internal data loader\n",
    "internal_loader = tc.PPNRInternalLoader(\n",
    "    in_sample_start=\"2018-01-01\",\n",
    "    in_sample_end=\"2019-06-30\"\n",
    ")\n",
    "internal_loader.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Create and load MEV loader\n",
    "mev_loader = tc.MEVLoader()\n",
    "mev_loader.load('fake_scens.xlsx', sheet='base')  # Load model MEVs\n",
    "mev_loader.load_scens(            # Load scenario MEVs\n",
    "    'fake_scens.xlsx',\n",
    "    scens={\"Base\": \"base\", \"Adverse\": \"adv\", \"Severe\": \"sev\"}\n",
    ")\n",
    "\n",
    "# Create DataManager\n",
    "dm = tc.DataManager(internal_loader, mev_loader)\n",
    "\n",
    "# Test basic data access\n",
    "print(\"Internal Data Shape:\", dm.internal_data.shape)\n",
    "print(\"Internal Data Columns:\", dm.internal_data.columns.tolist())\n",
    "print(\"\\nIn-Sample Data Range:\")\n",
    "print(f\"Start: {dm.internal_in.index.min()}\")\n",
    "print(f\"End: {dm.internal_in.index.max()}\")\n",
    "print(\"\\nOut-Sample Data Range:\")\n",
    "print(f\"Start: {dm.internal_out.index.min()}\")\n",
    "print(f\"End: {dm.internal_out.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Test MEV Data Interpolation and Caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MEV Data:\n",
      "Shape: (370, 7)\n",
      "Columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'M', 'Q']\n",
      "\n",
      "First few rows:\n",
      "nan               NGDP           PSR          PDI    UNRATE       CPI  M  Q\n",
      "2000-03-31  100.160000  10032.570000  8047.460000  3.640000  3.080000  3  1\n",
      "2000-04-30   99.896506  10049.097386  8036.334431  4.098958  2.067059  4  2\n",
      "2000-05-31   99.768751  10031.340067  8037.305959  4.332339  2.532845  5  2\n",
      "2000-06-30   99.740000   9996.180000  8044.020000  4.420000  3.960000  6  2\n",
      "2000-07-31   99.761353   9957.712737  8050.351074  4.466939  5.934583  7  3\n",
      "\n",
      "Verify cache is working (should be instant):\n",
      "Same object: True\n",
      "\n",
      "Time indicators:\n",
      "nan         M  Q\n",
      "2000-03-31  3  1\n",
      "2000-04-30  4  2\n",
      "2000-05-31  5  2\n",
      "2000-06-30  6  2\n",
      "2000-07-31  7  3\n"
     ]
    }
   ],
   "source": [
    "# Get model MEV data\n",
    "model_mev = dm.model_mev\n",
    "\n",
    "# Check interpolation results\n",
    "print(\"Model MEV Data:\")\n",
    "print(\"Shape:\", model_mev.shape)\n",
    "print(\"Columns:\", model_mev.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(model_mev.head())\n",
    "\n",
    "# Test caching by accessing again\n",
    "model_mev2 = dm.model_mev\n",
    "print(\"\\nVerify cache is working (should be instant):\")\n",
    "print(\"Same object:\", model_mev2 is model_mev)  # Should be True if caching works\n",
    "\n",
    "# Check time indicators\n",
    "print(\"\\nTime indicators:\")\n",
    "print(model_mev[['M', 'Q']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Test Scenario MEV Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario Sets: ['fake_scens']\n",
      "\n",
      "Scenario Set: fake_scens\n",
      "Scenarios: ['Severe', 'Adverse', 'Base']\n",
      "First scenario shape: (370, 7)\n",
      "First scenario columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'M', 'Q']\n",
      "\n",
      "First few rows:\n",
      "nan               NGDP          PSR          PDI    UNRATE       CPI  M  Q\n",
      "2000-03-31  120.190000  9029.310000  9656.950000  3.270000  3.690000  3  1\n",
      "2000-04-30  119.878426  9044.184086  9643.600764  3.691235  2.475176  4  2\n",
      "2000-05-31  119.726034  9028.203043  9644.765534  3.903280  3.035652  5  2\n",
      "2000-06-30  119.690000  8996.560000  9652.820000  3.980000  4.750000  6  2\n",
      "2000-07-31  119.712911  8961.940402  9660.414604  4.017966  7.121091  7  3\n"
     ]
    }
   ],
   "source": [
    "# Get scenario MEVs\n",
    "scen_mevs = dm.scen_mevs\n",
    "\n",
    "# Print structure and content\n",
    "print(\"Scenario Sets:\", list(scen_mevs.keys()))\n",
    "for set_name, scenarios in scen_mevs.items():\n",
    "    print(f\"\\nScenario Set: {set_name}\")\n",
    "    print(\"Scenarios:\", list(scenarios.keys()))\n",
    "    \n",
    "    # Print details of first scenario\n",
    "    first_scen = next(iter(scenarios.values()))\n",
    "    print(f\"First scenario shape: {first_scen.shape}\")\n",
    "    print(f\"First scenario columns: {first_scen.columns.tolist()}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(first_scen.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Test Data Modification Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Data after modifications:\n",
      "New columns: ['Fixed_balance', 'Fixed_price', 'Redeemable_balance', 'Redeemable_price', 'VR_balance', 'VR_price', 'Total_Balance', 'Balance_Growth']\n",
      "\n",
      "First few rows of new features:\n",
      "            Total_Balance  Balance_Growth\n",
      "Date                                     \n",
      "2018-01-31    3357.174994             NaN\n",
      "2018-02-28    3418.079229        0.018142\n",
      "2018-03-31    3494.869005        0.022466\n",
      "2018-04-30    3551.964168        0.016337\n",
      "2018-05-31    3604.177211        0.014700\n",
      "\n",
      "Model MEV after modifications:\n",
      "New columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'NGDP_per_UNRATE', 'M', 'Q']\n",
      "\n",
      "First few rows of new feature:\n",
      "2000-03-31    27.516484\n",
      "2000-04-30    24.920392\n",
      "2000-05-31    23.360011\n",
      "2000-06-30    22.565611\n",
      "2000-07-31    22.097281\n",
      "Freq: M, Name: NGDP_per_UNRATE, dtype: float64\n",
      "\n",
      "Scenario MEVs after modifications:\n",
      "\n",
      "Scenario Set: fake_scens\n",
      "Scenario Severe columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'NGDP_per_UNRATE', 'M', 'Q']\n",
      "Scenario Adverse columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'NGDP_per_UNRATE', 'M', 'Q']\n",
      "Scenario Base columns: ['NGDP', 'PSR', 'PDI', 'UNRATE', 'CPI', 'NGDP_per_UNRATE', 'M', 'Q']\n"
     ]
    }
   ],
   "source": [
    "# Test apply_to_internal\n",
    "def add_internal_features(df):\n",
    "    # Add a new column in-place\n",
    "    df['Total_Balance'] = df['Fixed_balance'] + df['Redeemable_balance'] + df['VR_balance']\n",
    "    \n",
    "    # Return a new feature\n",
    "    return pd.Series(\n",
    "        df['Total_Balance'].pct_change(),\n",
    "        name='Balance_Growth'\n",
    "    )\n",
    "\n",
    "dm.apply_to_internal(add_internal_features)\n",
    "\n",
    "# Verify changes\n",
    "print(\"Internal Data after modifications:\")\n",
    "print(\"New columns:\", dm.internal_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of new features:\")\n",
    "print(dm.internal_data[['Total_Balance', 'Balance_Growth']].head())\n",
    "\n",
    "# Test apply_to_mevs\n",
    "def add_mev_features(mev_df, internal_df):\n",
    "    # Add a ratio of two MEVs\n",
    "    mev_df['NGDP_per_UNRATE'] = mev_df['NGDP'] / mev_df['UNRATE']\n",
    "    return mev_df\n",
    "\n",
    "dm.apply_to_mevs(add_mev_features)\n",
    "\n",
    "# Verify changes in both model and scenario MEVs\n",
    "print(\"\\nModel MEV after modifications:\")\n",
    "print(\"New columns:\", dm.model_mev.columns.tolist())\n",
    "print(\"\\nFirst few rows of new feature:\")\n",
    "print(dm.model_mev['NGDP_per_UNRATE'].head())\n",
    "\n",
    "print(\"\\nScenario MEVs after modifications:\")\n",
    "for set_name, scenarios in dm.scen_mevs.items():\n",
    "    print(f\"\\nScenario Set: {set_name}\")\n",
    "    for scen_name, df in scenarios.items():\n",
    "        print(f\"Scenario {scen_name} columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Enhanced MEV Handling in DataManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample monthly and quarterly MEV data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create quarterly MEV data\n",
    "dates_qtr = pd.date_range('2018-01-01', '2023-12-31', freq='Q')\n",
    "mev_qtr = pd.DataFrame({\n",
    "    'GDP': np.random.normal(100, 10, len(dates_qtr)),\n",
    "    'UNRATE': np.random.normal(5, 1, len(dates_qtr)),\n",
    "    'CPI': np.random.normal(200, 20, len(dates_qtr))\n",
    "}, index=dates_qtr)\n",
    "\n",
    "# Create monthly MEV data with some overlapping variables\n",
    "dates_mth = pd.date_range('2018-01-01', '2023-12-31', freq='M')\n",
    "mev_mth = pd.DataFrame({\n",
    "    'GDP': np.random.normal(100, 10, len(dates_mth)),  # Overlapping with quarterly\n",
    "    'HOUSING': np.random.normal(150, 15, len(dates_mth)),  # Monthly only\n",
    "    'CPI': np.random.normal(200, 20, len(dates_mth))  # Overlapping with quarterly\n",
    "}, index=dates_mth)\n",
    "\n",
    "# Initialize MEV loader with sample MEV map\n",
    "mev_map = {\n",
    "    'GDP': {'type': 'level', 'description': 'Gross Domestic Product'},\n",
    "    'UNRATE': {'type': 'rate', 'description': 'Unemployment Rate'},\n",
    "    'CPI': {'type': 'level', 'description': 'Consumer Price Index'},\n",
    "    'HOUSING': {'type': 'level', 'description': 'Housing Index'}\n",
    "}\n",
    "\n",
    "# Create and load MEV loader\n",
    "mev_loader = tc.MEVLoader(mev_map=mev_map)\n",
    "mev_loader._model_mev_qtr = mev_qtr\n",
    "mev_loader._model_mev_mth = mev_mth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1: Monthly Frequency Data Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined MEV Data Structure:\n",
      "Total columns: 8\n",
      "\n",
      "Column names:\n",
      "- CPI\n",
      "- CPI_Q\n",
      "- GDP\n",
      "- GDP_Q\n",
      "- HOUSING\n",
      "- M\n",
      "- Q\n",
      "- UNRATE\n",
      "\n",
      "Verify MEV handling:\n",
      "1. Monthly-only variables (should be as-is):\n",
      "- HOUSING exists: True\n",
      "\n",
      "2. Overlapping variables:\n",
      "- Original monthly data:\n",
      "- GDP exists: True\n",
      "- Interpolated quarterly data with '_Q' suffix:\n",
      "- GDP_Q exists: True\n",
      "\n",
      "3. Quarterly-only variables:\n",
      "- UNRATE exists with '_Q' suffix: False\n",
      "\n",
      "MEV Map Updates:\n",
      "Derived MEV descriptions:\n",
      "- GDP_Q: Gross Domestic Product (Interpolated from quarterly)\n",
      "- CPI_Q: Consumer Price Index (Interpolated from quarterly)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create DataManager with monthly internal data\n",
    "data_ldr_mth = tc.PPNRInternalLoader(freq='M')\n",
    "data_ldr_mth.load(source='fake_internal.xlsx', date_col='Date')\n",
    "\n",
    "# Create DataManager\n",
    "dm_mth = tc.DataManager(data_ldr_mth, mev_loader)\n",
    "\n",
    "# Get combined MEV data\n",
    "mev_combined = dm_mth.model_mev\n",
    "\n",
    "# Check the results\n",
    "print(\"Combined MEV Data Structure:\")\n",
    "print(f\"Total columns: {len(mev_combined.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for col in sorted(mev_combined.columns):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\nVerify MEV handling:\")\n",
    "print(\"1. Monthly-only variables (should be as-is):\")\n",
    "print(f\"- HOUSING exists: {'HOUSING' in mev_combined.columns}\")\n",
    "\n",
    "print(\"\\n2. Overlapping variables:\")\n",
    "print(\"- Original monthly data:\")\n",
    "print(f\"- GDP exists: {'GDP' in mev_combined.columns}\")\n",
    "print(\"- Interpolated quarterly data with '_Q' suffix:\")\n",
    "print(f\"- GDP_Q exists: {'GDP_Q' in mev_combined.columns}\")\n",
    "\n",
    "print(\"\\n3. Quarterly-only variables:\")\n",
    "print(f\"- UNRATE exists with '_Q' suffix: {'UNRATE_Q' in mev_combined.columns}\")\n",
    "\n",
    "# Check if the MEV map was updated\n",
    "print(\"\\nMEV Map Updates:\")\n",
    "mev_map = dm_mth.mev_map\n",
    "print(\"Derived MEV descriptions:\")\n",
    "for code in ['GDP_Q', 'UNRATE_Q', 'CPI_Q']:\n",
    "    if code in mev_map:\n",
    "        print(f\"- {code}: {mev_map[code]['description']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2: Quarterly Frequency Data Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined MEV Data Structure:\n",
      "Total columns: 8\n",
      "\n",
      "Column names:\n",
      "- CPI\n",
      "- CPI_M\n",
      "- GDP\n",
      "- GDP_M\n",
      "- HOUSING\n",
      "- M\n",
      "- Q\n",
      "- UNRATE\n",
      "\n",
      "Verify MEV handling:\n",
      "1. Quarterly-only variables (should be as-is):\n",
      "- UNRATE exists: True\n",
      "\n",
      "2. Overlapping variables:\n",
      "- Original quarterly data:\n",
      "- GDP exists: True\n",
      "- Monthly-derived data with '_M' suffix:\n",
      "- GDP_M exists: True\n",
      "\n",
      "3. Monthly-only variables:\n",
      "- HOUSING exists with '_M' suffix: False\n",
      "\n",
      "MEV Map Updates:\n",
      "Derived MEV descriptions:\n",
      "- GDP_M: Gross Domestic Product (Averaged from monthly)\n",
      "- CPI_M: Consumer Price Index (Averaged from monthly)\n",
      "\n",
      "Quarterly Averaging Check:\n",
      "Checking if monthly data was properly averaged to quarters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create DataManager with quarterly internal data\n",
    "data_ldr_qtr = tc.PPNRInternalLoader(freq='Q')\n",
    "data_ldr_qtr.load(source='fake_internal.xlsx', date_col='Date')\n",
    "\n",
    "# Create DataManager\n",
    "dm_qtr = tc.DataManager(data_ldr_qtr, mev_loader)\n",
    "\n",
    "# Get combined MEV data\n",
    "mev_combined = dm_qtr.model_mev\n",
    "\n",
    "# Check the results\n",
    "print(\"Combined MEV Data Structure:\")\n",
    "print(f\"Total columns: {len(mev_combined.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for col in sorted(mev_combined.columns):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\nVerify MEV handling:\")\n",
    "print(\"1. Quarterly-only variables (should be as-is):\")\n",
    "print(f\"- UNRATE exists: {'UNRATE' in mev_combined.columns}\")\n",
    "\n",
    "print(\"\\n2. Overlapping variables:\")\n",
    "print(\"- Original quarterly data:\")\n",
    "print(f\"- GDP exists: {'GDP' in mev_combined.columns}\")\n",
    "print(\"- Monthly-derived data with '_M' suffix:\")\n",
    "print(f\"- GDP_M exists: {'GDP_M' in mev_combined.columns}\")\n",
    "\n",
    "print(\"\\n3. Monthly-only variables:\")\n",
    "print(f\"- HOUSING exists with '_M' suffix: {'HOUSING_M' in mev_combined.columns}\")\n",
    "\n",
    "# Check if the MEV map was updated\n",
    "print(\"\\nMEV Map Updates:\")\n",
    "mev_map = dm_qtr.mev_map\n",
    "print(\"Derived MEV descriptions:\")\n",
    "for code in ['GDP_M', 'HOUSING_M', 'CPI_M']:\n",
    "    if code in mev_map:\n",
    "        print(f\"- {code}: {mev_map[code]['description']}\")\n",
    "\n",
    "# Verify quarterly averaging\n",
    "print(\"\\nQuarterly Averaging Check:\")\n",
    "print(\"Checking if monthly data was properly averaged to quarters...\")\n",
    "\n",
    "# Get a sample overlapping variable (GDP)\n",
    "if 'GDP' in mev_combined.columns and 'GDP_M' in mev_combined.columns:\n",
    "    sample_quarter = mev_combined.index[0]\n",
    "    monthly_data = mev_mth.loc[f\"{sample_quarter.year}-{sample_quarter.quarter}\"]\n",
    "    if len(monthly_data) == 3:  # Only check if we have all 3 months\n",
    "        expected_avg = monthly_data['GDP'].mean()\n",
    "        actual_avg = mev_combined.loc[sample_quarter, 'GDP_M']\n",
    "        print(f\"\\nFor quarter {sample_quarter}:\")\n",
    "        print(f\"Monthly values: {monthly_data['GDP'].values}\")\n",
    "        print(f\"Calculated quarterly average: {expected_avg:.4f}\")\n",
    "        print(f\"Value in combined data: {actual_avg:.4f}\")\n",
    "        print(f\"Averages match: {abs(expected_avg - actual_avg) < 1e-10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3: Refresh and Cache Behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial access:\n",
      "Number of columns: 8\n",
      "\n",
      "Second access (should use cache):\n",
      "Same object: True\n",
      "\n",
      "Modifying MEV data and refreshing:\n",
      "Still using cache: False\n",
      "New data after refresh: False\n",
      "\n",
      "Verifying data update:\n",
      "GDP_Q values changed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test cache behavior and refresh functionality\n",
    "dm = tc.DataManager(data_ldr_mth, mev_loader)\n",
    "\n",
    "# First access to trigger cache creation\n",
    "print(\"Initial access:\")\n",
    "mev1 = dm.model_mev\n",
    "print(f\"Number of columns: {len(mev1.columns)}\")\n",
    "\n",
    "# Second access should use cache\n",
    "print(\"\\nSecond access (should use cache):\")\n",
    "mev2 = dm.model_mev\n",
    "print(f\"Same object: {mev1 is mev2}\")  # Should be True due to caching\n",
    "\n",
    "# Modify MEV data\n",
    "print(\"\\nModifying MEV data and refreshing:\")\n",
    "new_gdp = np.random.normal(100, 10, len(mev_qtr))\n",
    "mev_loader._model_mev_qtr['GDP'] = new_gdp\n",
    "\n",
    "# Access without refresh (should still use cache)\n",
    "mev3 = dm.model_mev\n",
    "print(f\"Still using cache: {mev1 is mev3}\")  # Should be True\n",
    "\n",
    "# Refresh and access again\n",
    "dm.refresh()\n",
    "mev4 = dm.model_mev\n",
    "print(f\"New data after refresh: {mev1 is mev4}\")  # Should be False\n",
    "\n",
    "# Verify data was actually updated\n",
    "print(\"\\nVerifying data update:\")\n",
    "if 'GDP_Q' in mev4.columns:\n",
    "    print(\"GDP_Q values changed:\", not (mev1['GDP_Q'] == mev4['GDP_Q']).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4: Suffix Addition Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Monthly Frequency Data\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in combined data:\n",
      "- CPI\n",
      "- CPI_Q\n",
      "- GDP\n",
      "- GDP_Q\n",
      "- HOUSING\n",
      "- M\n",
      "- Q\n",
      "- UNRATE\n",
      "\n",
      "Verifying suffix logic:\n",
      "1. Overlapping variables (should have both original and _Q):\n",
      "- GDP exists: True\n",
      "- GDP_Q exists: True\n",
      "- CPI exists: True\n",
      "- CPI_Q exists: True\n",
      "\n",
      "2. Non-overlapping variables (should NOT have suffix):\n",
      "- UNRATE exists without suffix: True\n",
      "- UNRATE_Q does NOT exist: True\n",
      "- HOUSING exists without suffix: True\n",
      "\n",
      "Test 2: Quarterly Frequency Data\n",
      "--------------------------------------------------\n",
      "Column names in combined data:\n",
      "- CPI\n",
      "- CPI_M\n",
      "- GDP\n",
      "- GDP_M\n",
      "- HOUSING\n",
      "- M\n",
      "- Q\n",
      "- UNRATE\n",
      "\n",
      "Verifying suffix logic:\n",
      "1. Overlapping variables (should have both original and _M):\n",
      "- GDP exists: True\n",
      "- GDP_M exists: True\n",
      "- CPI exists: True\n",
      "- CPI_M exists: True\n",
      "\n",
      "2. Non-overlapping variables (should NOT have suffix):\n",
      "- UNRATE exists without suffix: True\n",
      "- HOUSING exists without suffix: True\n",
      "- HOUSING_M does NOT exist: True\n",
      "\n",
      "MEV Map Updates\n",
      "--------------------------------------------------\n",
      "1. Checking derived MEVs in map:\n",
      "Overlapping variables (should have derived entries):\n",
      "- GDP_Q: Gross Domestic Product (Interpolated from quarterly)\n",
      "- CPI_Q: Consumer Price Index (Interpolated from quarterly)\n",
      "- GDP_M: Gross Domestic Product (Averaged from monthly)\n",
      "- CPI_M: Consumer Price Index (Averaged from monthly)\n",
      "\n",
      "Non-overlapping variables (should NOT have derived entries):\n",
      "- UNRATE_Q exists in map: False\n",
      "- HOUSING_M exists in map: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test suffix addition logic for overlapping vs non-overlapping variables\n",
    "\n",
    "# Create test data with specific overlap patterns\n",
    "dates_qtr = pd.date_range('2018-01-01', '2023-12-31', freq='Q')\n",
    "dates_mth = pd.date_range('2018-01-01', '2023-12-31', freq='M')\n",
    "\n",
    "# Quarterly data:\n",
    "# - GDP: overlaps with monthly\n",
    "# - UNRATE: quarterly only\n",
    "# - CPI: overlaps with monthly\n",
    "mev_qtr_test = pd.DataFrame({\n",
    "    'GDP': np.random.normal(100, 10, len(dates_qtr)),\n",
    "    'UNRATE': np.random.normal(5, 1, len(dates_qtr)),\n",
    "    'CPI': np.random.normal(200, 20, len(dates_qtr))\n",
    "}, index=dates_qtr)\n",
    "\n",
    "# Monthly data:\n",
    "# - GDP: overlaps with quarterly\n",
    "# - HOUSING: monthly only\n",
    "# - CPI: overlaps with quarterly\n",
    "mev_mth_test = pd.DataFrame({\n",
    "    'GDP': np.random.normal(100, 10, len(dates_mth)),\n",
    "    'HOUSING': np.random.normal(150, 15, len(dates_mth)),\n",
    "    'CPI': np.random.normal(200, 20, len(dates_mth))\n",
    "}, index=dates_mth)\n",
    "\n",
    "# Update MEV loader with test data\n",
    "mev_loader._model_mev_qtr = mev_qtr_test\n",
    "mev_loader._model_mev_mth = mev_mth_test\n",
    "\n",
    "print(\"Test 1: Monthly Frequency Data\")\n",
    "print(\"-\" * 50)\n",
    "dm_mth = tc.DataManager(data_ldr_mth, mev_loader)\n",
    "mev_monthly = dm_mth.model_mev\n",
    "\n",
    "print(\"Column names in combined data:\")\n",
    "for col in sorted(mev_monthly.columns):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\nVerifying suffix logic:\")\n",
    "print(\"1. Overlapping variables (should have both original and _Q):\")\n",
    "print(f\"- GDP exists: {'GDP' in mev_monthly.columns}\")\n",
    "print(f\"- GDP_Q exists: {'GDP_Q' in mev_monthly.columns}\")\n",
    "print(f\"- CPI exists: {'CPI' in mev_monthly.columns}\")\n",
    "print(f\"- CPI_Q exists: {'CPI_Q' in mev_monthly.columns}\")\n",
    "\n",
    "print(\"\\n2. Non-overlapping variables (should NOT have suffix):\")\n",
    "print(f\"- UNRATE exists without suffix: {'UNRATE' in mev_monthly.columns}\")\n",
    "print(f\"- UNRATE_Q does NOT exist: {'UNRATE_Q' not in mev_monthly.columns}\")\n",
    "print(f\"- HOUSING exists without suffix: {'HOUSING' in mev_monthly.columns}\")\n",
    "\n",
    "print(\"\\nTest 2: Quarterly Frequency Data\")\n",
    "print(\"-\" * 50)\n",
    "dm_qtr = tc.DataManager(data_ldr_qtr, mev_loader)\n",
    "mev_quarterly = dm_qtr.model_mev\n",
    "\n",
    "print(\"Column names in combined data:\")\n",
    "for col in sorted(mev_quarterly.columns):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\nVerifying suffix logic:\")\n",
    "print(\"1. Overlapping variables (should have both original and _M):\")\n",
    "print(f\"- GDP exists: {'GDP' in mev_quarterly.columns}\")\n",
    "print(f\"- GDP_M exists: {'GDP_M' in mev_quarterly.columns}\")\n",
    "print(f\"- CPI exists: {'CPI' in mev_quarterly.columns}\")\n",
    "print(f\"- CPI_M exists: {'CPI_M' in mev_quarterly.columns}\")\n",
    "\n",
    "print(\"\\n2. Non-overlapping variables (should NOT have suffix):\")\n",
    "print(f\"- UNRATE exists without suffix: {'UNRATE' in mev_quarterly.columns}\")\n",
    "print(f\"- HOUSING exists without suffix: {'HOUSING' in mev_quarterly.columns}\")\n",
    "print(f\"- HOUSING_M does NOT exist: {'HOUSING_M' not in mev_quarterly.columns}\")\n",
    "\n",
    "# Verify MEV map updates\n",
    "print(\"\\nMEV Map Updates\")\n",
    "print(\"-\" * 50)\n",
    "mev_map = dm_mth.mev_map\n",
    "print(\"1. Checking derived MEVs in map:\")\n",
    "print(\"Overlapping variables (should have derived entries):\")\n",
    "for code in ['GDP_Q', 'CPI_Q', 'GDP_M', 'CPI_M']:\n",
    "    if code in mev_map:\n",
    "        print(f\"- {code}: {mev_map[code]['description']}\")\n",
    "\n",
    "print(\"\\nNon-overlapping variables (should NOT have derived entries):\")\n",
    "for code in ['UNRATE_Q', 'HOUSING_M']:\n",
    "    print(f\"- {code} exists in map: {code in mev_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 5: Transform Specification Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:755: UserWarning: No type mapping for variables: ['NonExistentVar'], using raw-only\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building transform specifications...\n",
      "\n",
      "Results for each variable:\n",
      "\n",
      "GDP:\n",
      "Transforms:\n",
      "- TSFM:GDP_LV\n",
      "- TSFM:GDP_LV_L1\n",
      "- TSFM:GDP_GR\n",
      "- TSFM:GDP_GR_L1\n",
      "- TSFM:GDP_GR2\n",
      "- TSFM:GDP_GR2_L1\n",
      "\n",
      "UNRATE:\n",
      "Transforms:\n",
      "- TSFM:UNRATE_LV\n",
      "- TSFM:UNRATE_LV_L1\n",
      "- TSFM:UNRATE_DF\n",
      "- TSFM:UNRATE_DF_L1\n",
      "- TSFM:UNRATE_DF2\n",
      "- TSFM:UNRATE_DF2_L1\n",
      "- TSFM:UNRATE_GR\n",
      "- TSFM:UNRATE_GR_L1\n",
      "- TSFM:UNRATE_GR2\n",
      "- TSFM:UNRATE_GR2_L1\n",
      "\n",
      "HOUSING:\n",
      "Transforms:\n",
      "- TSFM:HOUSING_LV\n",
      "- TSFM:HOUSING_LV_L1\n",
      "- TSFM:HOUSING_GR\n",
      "- TSFM:HOUSING_GR_L1\n",
      "- TSFM:HOUSING_GR2\n",
      "- TSFM:HOUSING_GR2_L1\n",
      "\n",
      "NonExistentVar:\n",
      "- Raw only (no type mapping)\n",
      "\n",
      "Testing build_search_vars...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Feature 'NonExistentVar' not found in data sources.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Test build_search_vars\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting build_search_vars...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m var_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mdm_mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_search_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated features for each variable:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var, df \u001b[38;5;129;01min\u001b[39;00m var_dfs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32me:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:819\u001b[0m, in \u001b[0;36mDataManager.build_search_vars\u001b[1;34m(self, specs, max_lag, max_periods)\u001b[0m\n\u001b[0;32m    817\u001b[0m var_df_map: Dict[\u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var, tsfms \u001b[38;5;129;01min\u001b[39;00m tsfm_specs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 819\u001b[0m     var_df_map[var] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsfms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m var_df_map\n",
      "File \u001b[1;32me:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:642\u001b[0m, in \u001b[0;36mDataManager.build_features\u001b[1;34m(self, specs, internal_df, mev_df)\u001b[0m\n\u001b[0;32m    640\u001b[0m         pieces\u001b[38;5;241m.\u001b[39mappend(data_mev[spec])\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in data sources.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid spec type after flatten(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Feature 'NonExistentVar' not found in data sources.\""
     ]
    }
   ],
   "source": [
    "# Test transform specification building with different variable types\n",
    "from Technic.transform import TSFM\n",
    "\n",
    "# Create test variables with different types\n",
    "test_vars = ['GDP', 'UNRATE', 'HOUSING', 'NonExistentVar']\n",
    "\n",
    "# Build transform specifications\n",
    "print(\"Building transform specifications...\")\n",
    "specs = dm_mth.build_tsfm_specs(test_vars, max_lag=1, max_periods=2)\n",
    "\n",
    "print(\"\\nResults for each variable:\")\n",
    "for var, transforms in specs.items():\n",
    "    print(f\"\\n{var}:\")\n",
    "    if isinstance(transforms[0], str):\n",
    "        print(\"- Raw only (no type mapping)\")\n",
    "    else:\n",
    "        print(\"Transforms:\")\n",
    "        for t in transforms:\n",
    "            print(f\"- {t}\")\n",
    "\n",
    "# Test build_search_vars\n",
    "print(\"\\nTesting build_search_vars...\")\n",
    "var_dfs = dm_mth.build_search_vars(test_vars, max_lag=1, max_periods=2)\n",
    "\n",
    "print(\"\\nGenerated features for each variable:\")\n",
    "for var, df in var_dfs.items():\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(\"Features:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Testing Combined Quarterly and Monthly MEV Data\n",
    "\n",
    "This section tests the new functionality in DataManager that handles both quarterly and monthly MEV data, including:\n",
    "1. Combining quarterly and monthly model MEVs\n",
    "2. Combining quarterly and monthly scenario MEVs\n",
    "3. Handling overlapping variables with appropriate suffixes\n",
    "4. Verifying data frequency matches internal data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic scenario data...\n",
      "--------------------------------------------------\n",
      "Created scenario data:\n",
      "\n",
      "Quarterly scenarios:\n",
      "\n",
      "Scenario set: EWST2024\n",
      "- Base shape: (24, 3), variables: ['GDP', 'UNRATE', 'CPI']\n",
      "- Adverse shape: (24, 3), variables: ['GDP', 'UNRATE', 'CPI']\n",
      "\n",
      "Monthly scenarios:\n",
      "\n",
      "Scenario set: EWST2024\n",
      "- Base shape: (72, 3), variables: ['GDP', 'HOUSING', 'CPI']\n",
      "- Adverse shape: (72, 3), variables: ['GDP', 'HOUSING', 'CPI']\n",
      "\n",
      "Testing combined scenarios...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic scenario data for testing\n",
    "print(\"Creating synthetic scenario data...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create date ranges\n",
    "dates_qtr = pd.date_range('2018-01-01', '2023-12-31', freq='Q')\n",
    "dates_mth = pd.date_range('2018-01-01', '2023-12-31', freq='M')\n",
    "\n",
    "# Create quarterly scenario data\n",
    "scen_qtr = {\n",
    "    'EWST2024': {\n",
    "        'Base': pd.DataFrame({\n",
    "            'GDP': np.random.normal(100, 5, len(dates_qtr)),\n",
    "            'UNRATE': np.random.normal(5, 0.5, len(dates_qtr)),\n",
    "            'CPI': np.random.normal(200, 10, len(dates_qtr))\n",
    "        }, index=dates_qtr),\n",
    "        'Adverse': pd.DataFrame({\n",
    "            'GDP': np.random.normal(90, 5, len(dates_qtr)),\n",
    "            'UNRATE': np.random.normal(7, 0.5, len(dates_qtr)),\n",
    "            'CPI': np.random.normal(220, 10, len(dates_qtr))\n",
    "        }, index=dates_qtr)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create monthly scenario data\n",
    "scen_mth = {\n",
    "    'EWST2024': {\n",
    "        'Base': pd.DataFrame({\n",
    "            'GDP': np.random.normal(100, 2, len(dates_mth)),\n",
    "            'HOUSING': np.random.normal(150, 5, len(dates_mth)),\n",
    "            'CPI': np.random.normal(200, 5, len(dates_mth))\n",
    "        }, index=dates_mth),\n",
    "        'Adverse': pd.DataFrame({\n",
    "            'GDP': np.random.normal(90, 2, len(dates_mth)),\n",
    "            'HOUSING': np.random.normal(130, 5, len(dates_mth)),\n",
    "            'CPI': np.random.normal(220, 5, len(dates_mth))\n",
    "        }, index=dates_mth)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update MEV loader with synthetic data\n",
    "dm._mev_loader._scen_mev_qtr = scen_qtr\n",
    "dm._mev_loader._scen_mev_mth = scen_mth\n",
    "\n",
    "# Force refresh to clear caches\n",
    "dm.refresh()\n",
    "\n",
    "print(\"Created scenario data:\")\n",
    "print(\"\\nQuarterly scenarios:\")\n",
    "for set_name, scenarios in scen_qtr.items():\n",
    "    print(f\"\\nScenario set: {set_name}\")\n",
    "    for scen_name, df in scenarios.items():\n",
    "        print(f\"- {scen_name} shape: {df.shape}, variables: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\nMonthly scenarios:\")\n",
    "for set_name, scenarios in scen_mth.items():\n",
    "    print(f\"\\nScenario set: {set_name}\")\n",
    "    for scen_name, df in scenarios.items():\n",
    "        print(f\"- {scen_name} shape: {df.shape}, variables: {list(df.columns)}\")\n",
    "\n",
    "# Now test the combined scenario data\n",
    "print(\"\\nTesting combined scenarios...\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Testing dictionary structure:\n",
      "Number of scenario sets: 1\n",
      "\n",
      "Scenario set: EWST2024\n",
      "Number of scenarios: 2\n",
      "Available scenarios: ['Adverse', 'Base']\n",
      "\n",
      "2. Testing data combination:\n",
      "\n",
      "Scenario set: EWST2024\n",
      "\n",
      "Scenario: Adverse\n",
      "Variable counts:\n",
      "- Base variables: 4\n",
      "- Quarterly-derived: 2\n",
      "- Monthly-derived: 0\n",
      "\n",
      "Frequency indicators:\n",
      "- Month column (M): True\n",
      "- Quarter column (Q): True\n",
      "\n",
      "Frequency check:\n",
      "- Internal data frequency: M\n",
      "- Scenario data frequency: M\n",
      "\n",
      "Sample of overlapping variable:\n",
      "Variable: CPI\n",
      "                   CPI       CPI_Q\n",
      "2018-01-31  219.492299         NaN\n",
      "2018-02-28  221.698095         NaN\n",
      "2018-03-31  230.696906  234.243527\n",
      "2018-04-30  217.746060  216.907167\n",
      "2018-05-31  228.080042  207.848883\n",
      "\n",
      "Scenario: Base\n",
      "Variable counts:\n",
      "- Base variables: 4\n",
      "- Quarterly-derived: 2\n",
      "- Monthly-derived: 0\n",
      "\n",
      "Frequency indicators:\n",
      "- Month column (M): True\n",
      "- Quarter column (Q): True\n",
      "\n",
      "Frequency check:\n",
      "- Internal data frequency: M\n",
      "- Scenario data frequency: M\n",
      "\n",
      "Sample of overlapping variable:\n",
      "Variable: CPI\n",
      "                   CPI       CPI_Q\n",
      "2018-01-31  213.150677         NaN\n",
      "2018-02-28  200.315958         NaN\n",
      "2018-03-31  203.199878  204.328836\n",
      "2018-04-30  200.293496  193.444112\n",
      "2018-05-31  204.337197  193.264237\n"
     ]
    }
   ],
   "source": [
    "# Get combined scenario data\n",
    "scenarios = dm.scen_mevs\n",
    "\n",
    "# Test 1: Check dictionary structure\n",
    "print(\"\\n1. Testing dictionary structure:\")\n",
    "print(f\"Number of scenario sets: {len(scenarios)}\")\n",
    "for scen_set, scen_dict in scenarios.items():\n",
    "    print(f\"\\nScenario set: {scen_set}\")\n",
    "    print(f\"Number of scenarios: {len(scen_dict)}\")\n",
    "    print(f\"Available scenarios: {list(scen_dict.keys())}\")\n",
    "\n",
    "# Test 2: Check data combination for each scenario\n",
    "print(\"\\n2. Testing data combination:\")\n",
    "for scen_set, scen_dict in scenarios.items():\n",
    "    print(f\"\\nScenario set: {scen_set}\")\n",
    "    for scen_name, scen_df in scen_dict.items():\n",
    "        print(f\"\\nScenario: {scen_name}\")\n",
    "        \n",
    "        # Check if we have both quarterly and monthly data\n",
    "        qtr_vars = [col for col in scen_df.columns if col.endswith('_Q')]\n",
    "        mth_vars = [col for col in scen_df.columns if col.endswith('_M')]\n",
    "        base_vars = [col for col in scen_df.columns \n",
    "                    if not col.endswith(('_Q', '_M')) \n",
    "                    and col not in ['M', 'Q']]\n",
    "        \n",
    "        print(\"Variable counts:\")\n",
    "        print(f\"- Base variables: {len(base_vars)}\")\n",
    "        print(f\"- Quarterly-derived: {len(qtr_vars)}\")\n",
    "        print(f\"- Monthly-derived: {len(mth_vars)}\")\n",
    "        \n",
    "        # Check frequency indicators\n",
    "        print(\"\\nFrequency indicators:\")\n",
    "        print(f\"- Month column (M): {'M' in scen_df.columns}\")\n",
    "        print(f\"- Quarter column (Q): {'Q' in scen_df.columns}\")\n",
    "        \n",
    "        # Verify data frequency matches internal data\n",
    "        internal_freq = pd.infer_freq(dm.internal_data.index)\n",
    "        scen_freq = pd.infer_freq(scen_df.index)\n",
    "        print(f\"\\nFrequency check:\")\n",
    "        print(f\"- Internal data frequency: {internal_freq}\")\n",
    "        print(f\"- Scenario data frequency: {scen_freq}\")\n",
    "        \n",
    "        # Sample of overlapping variables\n",
    "        overlap_vars = set(qtr_vars).intersection({f\"{v}_Q\" for v in base_vars})\n",
    "        if overlap_vars:\n",
    "            print(\"\\nSample of overlapping variable:\")\n",
    "            var = next(iter(overlap_vars))\n",
    "            base_var = var[:-2]  # Remove _Q suffix\n",
    "            print(f\"Variable: {base_var}\")\n",
    "            print(scen_df[[base_var, var]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Testing specific variable handling:\n",
      "\n",
      "Variable categories in Base scenario:\n",
      "a) Monthly-only variables:\n",
      "- HOUSING exists: True\n",
      "\n",
      "b) Overlapping variables (GDP, CPI):\n",
      "GDP handling:\n",
      "- Monthly GDP exists: True\n",
      "- Quarterly GDP (_Q) exists: True\n",
      "\n",
      "CPI handling:\n",
      "- Monthly CPI exists: True\n",
      "- Quarterly CPI (_Q) exists: True\n",
      "\n",
      "c) Quarterly-only variables:\n",
      "- UNRATE exists: True\n",
      "\n",
      "4. Testing caching:\n",
      "Time to retrieve from cache: 10.97ms\n",
      "Time to recompute after refresh: 27.92ms\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Check specific variable handling\n",
    "print(\"\\n3. Testing specific variable handling:\")\n",
    "first_scen = scenarios['EWST2024']['Base']\n",
    "print(\"\\nVariable categories in Base scenario:\")\n",
    "print(\"a) Monthly-only variables:\")\n",
    "print(f\"- HOUSING exists: {'HOUSING' in first_scen.columns}\")\n",
    "\n",
    "print(\"\\nb) Overlapping variables (GDP, CPI):\")\n",
    "print(\"GDP handling:\")\n",
    "print(f\"- Monthly GDP exists: {'GDP' in first_scen.columns}\")\n",
    "print(f\"- Quarterly GDP (_Q) exists: {'GDP_Q' in first_scen.columns}\")\n",
    "print(\"\\nCPI handling:\")\n",
    "print(f\"- Monthly CPI exists: {'CPI' in first_scen.columns}\")\n",
    "print(f\"- Quarterly CPI (_Q) exists: {'CPI_Q' in first_scen.columns}\")\n",
    "\n",
    "print(\"\\nc) Quarterly-only variables:\")\n",
    "print(f\"- UNRATE exists: {'UNRATE' in first_scen.columns}\")\n",
    "\n",
    "# Test 4: Verify caching\n",
    "print(\"\\n4. Testing caching:\")\n",
    "# Get scenarios again and verify it's using cache\n",
    "import time\n",
    "start = time.time()\n",
    "scenarios2 = dm.scen_mevs\n",
    "end = time.time()\n",
    "print(f\"Time to retrieve from cache: {(end-start)*1000:.2f}ms\")\n",
    "\n",
    "# Force refresh and measure time\n",
    "dm.refresh()\n",
    "start = time.time()\n",
    "scenarios3 = dm.scen_mevs\n",
    "end = time.time()\n",
    "print(f\"Time to recompute after refresh: {(end-start)*1000:.2f}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Testing Scenario MEVs with Quarterly Internal Data\n",
    "\n",
    "Now we'll test how scenario MEVs are handled when the internal data is quarterly frequency. This should:\n",
    "1. Convert monthly data to quarterly averages\n",
    "2. Add '_M' suffix to monthly-derived variables\n",
    "3. Keep quarterly-only variables as-is\n",
    "4. Maintain proper frequency alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing quarterly frequency scenario data...\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing data structure and frequency:\n",
      "\n",
      "Scenario set: EWST2024\n",
      "\n",
      "Scenario: Adverse\n",
      "Data frequency: Q-DEC\n",
      "\n",
      "Variable counts:\n",
      "- Base variables: 4\n",
      "- Monthly-derived (_M): 2\n",
      "- Quarterly-derived (_Q): 0\n",
      "\n",
      "Variable categories:\n",
      "a) Quarterly variables (no suffix):\n",
      "['GDP', 'UNRATE', 'CPI']\n",
      "\n",
      "b) Monthly-derived variables (_M):\n",
      "['CPI_M', 'GDP_M']\n",
      "\n",
      "Scenario: Base\n",
      "Data frequency: Q-DEC\n",
      "\n",
      "Variable counts:\n",
      "- Base variables: 4\n",
      "- Monthly-derived (_M): 2\n",
      "- Quarterly-derived (_Q): 0\n",
      "\n",
      "Variable categories:\n",
      "a) Quarterly variables (no suffix):\n",
      "['GDP', 'UNRATE', 'CPI']\n",
      "\n",
      "b) Monthly-derived variables (_M):\n",
      "['CPI_M', 'GDP_M']\n",
      "\n",
      "2. Testing quarterly averaging of monthly data:\n",
      "\n",
      "Checking averaging for quarter 2018-03-31 00:00:00:\n",
      "\n",
      "GDP averaging check:\n",
      "Monthly values: [101.53049673 101.19942478  99.98648015]\n",
      "Calculated average: 100.9055\n",
      "Value in quarterly data: 100.9055\n",
      "Averages match: True\n",
      "\n",
      "3. Testing specific variable handling:\n",
      "\n",
      "a) Monthly-only variables:\n",
      "- HOUSING exists with _M suffix: False\n",
      "- HOUSING exists without suffix: True\n",
      "\n",
      "b) Overlapping variables:\n",
      "GDP handling:\n",
      "- Quarterly GDP exists: True\n",
      "- Monthly-derived GDP exists: True\n",
      "\n",
      "c) Quarterly-only variables:\n",
      "- UNRATE exists without suffix: True\n",
      "- UNRATE does not have _M suffix: True\n",
      "\n",
      "4. Testing caching with quarterly data:\n",
      "Time to retrieve from cache: 7.98ms\n",
      "Time to recompute after refresh: 13.96ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Git\\Project_LEGO\\Technic\\data.py:143: UserWarning: Both monthly and quarterly MEVs detected with overlapping codes: ['CPI', 'GDP']. For monthly frequency data, interpolated quarterly values will be suffixed with '_Q'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a DataManager with quarterly frequency\n",
    "data_ldr_qtr = tc.PPNRInternalLoader(freq='Q')\n",
    "data_ldr_qtr.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Create new DataManager with quarterly internal data\n",
    "dm_qtr = tc.DataManager(data_ldr_qtr, dm._mev_loader)\n",
    "\n",
    "# Get combined scenario data\n",
    "print(\"Testing quarterly frequency scenario data...\")\n",
    "print(\"-\" * 50)\n",
    "scenarios_qtr = dm_qtr.scen_mevs\n",
    "\n",
    "# Test 1: Check data structure and frequency\n",
    "print(\"\\n1. Testing data structure and frequency:\")\n",
    "for scen_set, scen_dict in scenarios_qtr.items():\n",
    "    print(f\"\\nScenario set: {scen_set}\")\n",
    "    for scen_name, scen_df in scen_dict.items():\n",
    "        print(f\"\\nScenario: {scen_name}\")\n",
    "        \n",
    "        # Verify quarterly frequency\n",
    "        freq = pd.infer_freq(scen_df.index)\n",
    "        print(f\"Data frequency: {freq}\")\n",
    "        \n",
    "        # Check variable types\n",
    "        qtr_vars = [col for col in scen_df.columns if col.endswith('_Q')]\n",
    "        mth_vars = [col for col in scen_df.columns if col.endswith('_M')]\n",
    "        base_vars = [col for col in scen_df.columns \n",
    "                    if not col.endswith(('_Q', '_M')) \n",
    "                    and col not in ['M', 'Q']]\n",
    "        \n",
    "        print(\"\\nVariable counts:\")\n",
    "        print(f\"- Base variables: {len(base_vars)}\")\n",
    "        print(f\"- Monthly-derived (_M): {len(mth_vars)}\")  # Should have _M suffix\n",
    "        print(f\"- Quarterly-derived (_Q): {len(qtr_vars)}\")  # Should be 0\n",
    "        \n",
    "        print(\"\\nVariable categories:\")\n",
    "        print(\"a) Quarterly variables (no suffix):\")\n",
    "        print([v for v in base_vars if v in scen_qtr[scen_set][scen_name].columns])\n",
    "        print(\"\\nb) Monthly-derived variables (_M):\")\n",
    "        print(mth_vars)\n",
    "\n",
    "# Test 2: Verify quarterly averaging of monthly data\n",
    "print(\"\\n2. Testing quarterly averaging of monthly data:\")\n",
    "base_scen = scenarios_qtr['EWST2024']['Base']\n",
    "base_scen_mth = scen_mth['EWST2024']['Base']\n",
    "\n",
    "# Take a sample quarter and verify averaging\n",
    "sample_quarter = base_scen.index[0]\n",
    "print(f\"\\nChecking averaging for quarter {sample_quarter}:\")\n",
    "\n",
    "# Get the corresponding monthly data\n",
    "quarter_start = pd.Timestamp(f\"{sample_quarter.year}-{sample_quarter.quarter*3-2}-01\")\n",
    "quarter_end = pd.Timestamp(f\"{sample_quarter.year}-{sample_quarter.quarter*3}-{31 if sample_quarter.quarter in [1,3] else 30}\")\n",
    "monthly_data = base_scen_mth.loc[quarter_start:quarter_end]\n",
    "\n",
    "# Check GDP averaging\n",
    "if 'GDP_M' in base_scen.columns:\n",
    "    monthly_gdp = monthly_data['GDP']\n",
    "    quarterly_avg = monthly_gdp.mean()\n",
    "    actual_value = base_scen.loc[sample_quarter, 'GDP_M']\n",
    "    \n",
    "    print(\"\\nGDP averaging check:\")\n",
    "    print(f\"Monthly values: {monthly_gdp.values}\")\n",
    "    print(f\"Calculated average: {quarterly_avg:.4f}\")\n",
    "    print(f\"Value in quarterly data: {actual_value:.4f}\")\n",
    "    print(f\"Averages match: {abs(quarterly_avg - actual_value) < 1e-10}\")\n",
    "\n",
    "# Test 3: Check specific variable handling\n",
    "print(\"\\n3. Testing specific variable handling:\")\n",
    "print(\"\\na) Monthly-only variables:\")\n",
    "print(f\"- HOUSING exists with _M suffix: {'HOUSING_M' in base_scen.columns}\")\n",
    "print(f\"- HOUSING exists without suffix: {'HOUSING' in base_scen.columns}\")\n",
    "\n",
    "print(\"\\nb) Overlapping variables:\")\n",
    "print(\"GDP handling:\")\n",
    "print(f\"- Quarterly GDP exists: {'GDP' in base_scen.columns}\")\n",
    "print(f\"- Monthly-derived GDP exists: {'GDP_M' in base_scen.columns}\")\n",
    "\n",
    "print(\"\\nc) Quarterly-only variables:\")\n",
    "print(f\"- UNRATE exists without suffix: {'UNRATE' in base_scen.columns}\")\n",
    "print(f\"- UNRATE does not have _M suffix: {'UNRATE_M' not in base_scen.columns}\")\n",
    "\n",
    "# Test 4: Verify caching for quarterly data\n",
    "print(\"\\n4. Testing caching with quarterly data:\")\n",
    "import time\n",
    "\n",
    "# First access (already done)\n",
    "start = time.time()\n",
    "scenarios_qtr2 = dm_qtr.scen_mevs\n",
    "end = time.time()\n",
    "print(f\"Time to retrieve from cache: {(end-start)*1000:.2f}ms\")\n",
    "\n",
    "# Force refresh and measure recomputation\n",
    "dm_qtr.refresh()\n",
    "start = time.time()\n",
    "scenarios_qtr3 = dm_qtr.scen_mevs\n",
    "end = time.time()\n",
    "print(f\"Time to recompute after refresh: {(end-start)*1000:.2f}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3: Cache Behavior and Refresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Cache and Refresh Behavior\n",
      "--------------------------------------------------\n",
      "1. Initial access:\n",
      "Shape: (72, 8)\n",
      "Columns: ['CPI', 'CPI_Q', 'GDP', 'GDP_Q', 'HOUSING', 'M', 'Q', 'UNRATE']\n",
      "\n",
      "2. Second access (should use cache):\n",
      "Same object: True\n",
      "\n",
      "3. Modifying scenario data:\n",
      "\n",
      "Access without refresh:\n",
      "Still using cache: False\n",
      "\n",
      "4. After refresh:\n",
      "New object after refresh: True\n",
      "\n",
      "5. Verifying data update:\n",
      "Original GDP_Q mean: 113.1997281294566\n",
      "Updated GDP_Q mean: 113.30053535825363\n",
      "Values changed: True\n"
     ]
    }
   ],
   "source": [
    "# Test cache behavior and refresh functionality\n",
    "print(\"Testing Cache and Refresh Behavior\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# First access to trigger cache creation\n",
    "print(\"1. Initial access:\")\n",
    "scen_mevs1 = dm_mth.scen_mevs\n",
    "base_scen1 = scen_mevs1['EWST2024']['Base']\n",
    "print(f\"Shape: {base_scen1.shape}\")\n",
    "print(f\"Columns: {sorted(base_scen1.columns)}\")\n",
    "\n",
    "# Second access should use cache\n",
    "print(\"\\n2. Second access (should use cache):\")\n",
    "scen_mevs2 = dm_mth.scen_mevs\n",
    "print(f\"Same object: {scen_mevs1 is scen_mevs2}\")  # Should be True due to caching\n",
    "\n",
    "# Modify scenario data\n",
    "print(\"\\n3. Modifying scenario data:\")\n",
    "new_gdp = np.random.normal(110, 10, len(dates_qtr))\n",
    "mev_loader._scen_mev_qtr['EWST2024']['Base']['GDP'] = new_gdp\n",
    "\n",
    "# Access without refresh (should still use cache)\n",
    "print(\"\\nAccess without refresh:\")\n",
    "scen_mevs3 = dm_mth.scen_mevs\n",
    "print(f\"Still using cache: {scen_mevs1 is scen_mevs3}\")  # Should be True\n",
    "\n",
    "# Refresh and access again\n",
    "print(\"\\n4. After refresh:\")\n",
    "dm_mth.refresh()\n",
    "scen_mevs4 = dm_mth.scen_mevs\n",
    "print(f\"New object after refresh: {scen_mevs1 is not scen_mevs4}\")  # Should be True\n",
    "\n",
    "# Verify data was actually updated\n",
    "base_scen4 = scen_mevs4['EWST2024']['Base']\n",
    "if 'GDP_Q' in base_scen4.columns:\n",
    "    print(\"\\n5. Verifying data update:\")\n",
    "    print(\"Original GDP_Q mean:\", base_scen1['GDP_Q'].mean())\n",
    "    print(\"Updated GDP_Q mean:\", base_scen4['GDP_Q'].mean())\n",
    "    print(\"Values changed:\", not (base_scen1['GDP_Q'] == base_scen4['GDP_Q']).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4: MEV Map Updates for Derived Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MEV Map Updates for Derived Variables\n",
      "--------------------------------------------------\n",
      "1. Monthly Frequency MEV Map:\n",
      "\n",
      "Original variables:\n",
      "- GDP: Gross Domestic Product\n",
      "- CPI: Consumer Price Index\n",
      "- UNRATE: Unemployment Rate\n",
      "- HOUSING: Housing Index\n",
      "\n",
      "Derived variables (with _Q suffix):\n",
      "- GDP_Q: Gross Domestic Product (Interpolated from quarterly)\n",
      "- CPI_Q: Consumer Price Index (Interpolated from quarterly)\n",
      "\n",
      "2. Quarterly Frequency MEV Map:\n",
      "\n",
      "Original variables:\n",
      "- GDP: Gross Domestic Product\n",
      "- CPI: Consumer Price Index\n",
      "- UNRATE: Unemployment Rate\n",
      "- HOUSING: Housing Index\n",
      "\n",
      "Derived variables (with _M suffix):\n",
      "- GDP_M: Gross Domestic Product (Averaged from monthly)\n",
      "- CPI_M: Consumer Price Index (Averaged from monthly)\n",
      "\n",
      "3. Verifying type preservation:\n",
      "\n",
      "Monthly frequency:\n",
      "- GDP type: level\n",
      "- GDP_Q type: level\n",
      "- CPI type: level\n",
      "- CPI_Q type: level\n",
      "\n",
      "Quarterly frequency:\n",
      "- GDP type: level\n",
      "- GDP_M type: level\n",
      "- CPI type: level\n",
      "- CPI_M type: level\n",
      "\n",
      "4. Verifying non-overlapping variables:\n",
      "Monthly frequency:\n",
      "- UNRATE_Q exists: False\n",
      "- HOUSING_Q exists: False\n",
      "\n",
      "Quarterly frequency:\n",
      "- UNRATE_M exists: False\n",
      "- HOUSING_M exists: False\n"
     ]
    }
   ],
   "source": [
    "# Test MEV map updates for derived variables\n",
    "print(\"Testing MEV Map Updates for Derived Variables\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get MEV maps from both monthly and quarterly DataManagers\n",
    "mev_map_mth = dm_mth.mev_map\n",
    "mev_map_qtr = dm_qtr.mev_map\n",
    "\n",
    "print(\"1. Monthly Frequency MEV Map:\")\n",
    "print(\"\\nOriginal variables:\")\n",
    "for var in ['GDP', 'CPI', 'UNRATE', 'HOUSING']:\n",
    "    if var in mev_map_mth:\n",
    "        print(f\"- {var}: {mev_map_mth[var]['description']}\")\n",
    "\n",
    "print(\"\\nDerived variables (with _Q suffix):\")\n",
    "for var in ['GDP_Q', 'CPI_Q']:\n",
    "    if var in mev_map_mth:\n",
    "        print(f\"- {var}: {mev_map_mth[var]['description']}\")\n",
    "\n",
    "print(\"\\n2. Quarterly Frequency MEV Map:\")\n",
    "print(\"\\nOriginal variables:\")\n",
    "for var in ['GDP', 'CPI', 'UNRATE', 'HOUSING']:\n",
    "    if var in mev_map_qtr:\n",
    "        print(f\"- {var}: {mev_map_qtr[var]['description']}\")\n",
    "\n",
    "print(\"\\nDerived variables (with _M suffix):\")\n",
    "for var in ['GDP_M', 'CPI_M']:\n",
    "    if var in mev_map_qtr:\n",
    "        print(f\"- {var}: {mev_map_qtr[var]['description']}\")\n",
    "\n",
    "# Verify type preservation\n",
    "print(\"\\n3. Verifying type preservation:\")\n",
    "print(\"\\nMonthly frequency:\")\n",
    "for base_var, derived_var in [('GDP', 'GDP_Q'), ('CPI', 'CPI_Q')]:\n",
    "    if base_var in mev_map_mth and derived_var in mev_map_mth:\n",
    "        print(f\"- {base_var} type: {mev_map_mth[base_var]['type']}\")\n",
    "        print(f\"- {derived_var} type: {mev_map_mth[derived_var]['type']}\")\n",
    "\n",
    "print(\"\\nQuarterly frequency:\")\n",
    "for base_var, derived_var in [('GDP', 'GDP_M'), ('CPI', 'CPI_M')]:\n",
    "    if base_var in mev_map_qtr and derived_var in mev_map_qtr:\n",
    "        print(f\"- {base_var} type: {mev_map_qtr[base_var]['type']}\")\n",
    "        print(f\"- {derived_var} type: {mev_map_qtr[derived_var]['type']}\")\n",
    "\n",
    "# Verify non-overlapping variables don't have derived entries\n",
    "print(\"\\n4. Verifying non-overlapping variables:\")\n",
    "print(\"Monthly frequency:\")\n",
    "print(f\"- UNRATE_Q exists: {'UNRATE_Q' in mev_map_mth}\")\n",
    "print(f\"- HOUSING_Q exists: {'HOUSING_Q' in mev_map_mth}\")\n",
    "\n",
    "print(\"\\nQuarterly frequency:\")\n",
    "print(f\"- UNRATE_M exists: {'UNRATE_M' in mev_map_qtr}\")\n",
    "print(f\"- HOUSING_M exists: {'HOUSING_M' in mev_map_qtr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Test Scenario Handling Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of EWST2024 Base scenario:\n",
      "            Fixed_balance   VR_balance    New_var1    New_var2\n",
      "2023-01-31    2366.987883  1801.524490   97.289476  190.043089\n",
      "2023-02-28    2022.591697  1335.185328  104.060320  200.097264\n",
      "2023-03-31    2679.154819  1410.885384  106.057025  234.706074\n",
      "2023-04-30    1957.075594  1378.650889  113.856633  169.025615\n",
      "2023-05-31    2134.052184  1492.980297  110.574169  209.999727\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create synthetic scenario data\n",
    "dates = pd.date_range(start='2023-01-01', end='2025-12-31', freq='M')\n",
    "\n",
    "# Function to create scenario data with some randomness\n",
    "def create_scenario_data(base_values, scenario_factor):\n",
    "    data = {}\n",
    "    for col, base in base_values.items():\n",
    "        # Add some random variation and trend based on scenario\n",
    "        noise = np.random.normal(0, 0.1, len(dates))\n",
    "        trend = np.linspace(0, scenario_factor, len(dates))\n",
    "        values = base * (1 + noise + trend)\n",
    "        data[col] = values\n",
    "    return pd.DataFrame(data, index=dates)\n",
    "\n",
    "# Base values for variables (ensure some overlap with internal data)\n",
    "base_values = {\n",
    "    'Fixed_balance': 2000,\n",
    "    'VR_balance': 1500,\n",
    "    'New_var1': 100,  # New variable not in internal data\n",
    "    'New_var2': 200   # New variable not in internal data\n",
    "}\n",
    "\n",
    "# Create two scenario sets\n",
    "scenario_sets = {\n",
    "    'EWST2024': {\n",
    "        'Base': create_scenario_data(base_values, 0.1),\n",
    "        'Adverse': create_scenario_data(base_values, -0.2),\n",
    "        'Severe': create_scenario_data(base_values, -0.4)\n",
    "    },\n",
    "    'EWST2025': {\n",
    "        'Base': create_scenario_data(base_values, 0.15),\n",
    "        'Adverse': create_scenario_data(base_values, -0.25)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print sample of the scenario data\n",
    "print(\"Sample of EWST2024 Base scenario:\")\n",
    "print(scenario_sets['EWST2024']['Base'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### Test 1: Loading Scenarios from Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.1: Loading multiple scenario sets\n",
      "\n",
      "Scenario sets loaded: ['EWST2024', 'EWST2025']\n",
      "\n",
      "Set 'EWST2024' scenarios: ['Base', 'Adverse', 'Severe']\n",
      "Columns in EWST2024/Base: ['Fixed_balance', 'VR_balance', 'New_var1', 'New_var2']\n",
      "\n",
      "Set 'EWST2025' scenarios: ['Base', 'Adverse']\n",
      "Columns in EWST2025/Base: ['Fixed_balance', 'VR_balance', 'New_var1', 'New_var2']\n",
      "\n",
      "Test 1.2: Loading single scenario set\n",
      "\n",
      "Scenario sets after single set load: ['EWST2024']\n",
      "Scenarios in EWST2024: ['Base', 'Adverse', 'Severe']\n"
     ]
    }
   ],
   "source": [
    "# Create a new loader instance\n",
    "scen_loader = tc.PPNRInternalLoader(freq='M')\n",
    "\n",
    "# Load the base internal data first\n",
    "scen_loader.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Test 1.1: Load full scenario sets dictionary\n",
    "print(\"Test 1.1: Loading multiple scenario sets\")\n",
    "scen_loader.load_scens(source=scenario_sets)\n",
    "\n",
    "# Verify the structure\n",
    "print(\"\\nScenario sets loaded:\", list(scen_loader.scen_internal_data.keys()))\n",
    "for set_name, scenarios in scen_loader.scen_internal_data.items():\n",
    "    print(f\"\\nSet '{set_name}' scenarios:\", list(scenarios.keys()))\n",
    "    print(f\"Columns in {set_name}/Base:\", list(scenarios['Base'].columns))\n",
    "\n",
    "# Test 1.2: Load single scenario set\n",
    "print(\"\\nTest 1.2: Loading single scenario set\")\n",
    "scen_loader.clean_scens()  # Clear previous scenarios\n",
    "scen_loader.load_scens(\n",
    "    source=scenario_sets['EWST2024'],\n",
    "    set_name='EWST2024'\n",
    ")\n",
    "\n",
    "print(\"\\nScenario sets after single set load:\", list(scen_loader.scen_internal_data.keys()))\n",
    "print(\"Scenarios in EWST2024:\", list(scen_loader.scen_internal_data['EWST2024'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### Test 2: Loading Scenarios from Excel and Validation Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2.1: Loading scenarios from Excel\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "scens mapping required when loading from Excel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 2.1: Loading scenarios from Excel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m scen_loader\u001b[38;5;241m.\u001b[39mclean_scens()  \u001b[38;5;66;03m# Clear previous scenarios\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mscen_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_scens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexcel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEWST2024\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScenarios loaded from Excel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(scen_loader\u001b[38;5;241m.\u001b[39mscen_internal_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEWST2024\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Test 2.2: Validation of common columns\u001b[39;00m\n",
      "File \u001b[1;32me:\\OneDrive\\Git\\Project_LEGO\\Technic\\internal.py:278\u001b[0m, in \u001b[0;36mDataLoader.load_scens\u001b[1;34m(self, source, scens, set_name, date_col, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Excel file\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scens:\n\u001b[1;32m--> 278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscens mapping required when loading from Excel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    280\u001b[0m         set_name \u001b[38;5;241m=\u001b[39m Path(source)\u001b[38;5;241m.\u001b[39mstem\n",
      "\u001b[1;31mValueError\u001b[0m: scens mapping required when loading from Excel"
     ]
    }
   ],
   "source": [
    "# First save scenario data to Excel for testing\n",
    "import os\n",
    "\n",
    "# Create a temporary Excel file with scenarios\n",
    "excel_path = 'test_scenarios.xlsx'\n",
    "with pd.ExcelWriter(excel_path) as writer:\n",
    "    # Save EWST2024 scenarios\n",
    "    for scen_name, df in scenario_sets['EWST2024'].items():\n",
    "        df.to_excel(writer, sheet_name=scen_name)\n",
    "\n",
    "# Test 2.1: Load scenarios from Excel\n",
    "print(\"Test 2.1: Loading scenarios from Excel\")\n",
    "scen_loader.clean_scens()  # Clear previous scenarios\n",
    "scen_loader.load_scens(\n",
    "    source=excel_path,\n",
    "    set_name='EWST2024',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "print(\"\\nScenarios loaded from Excel:\", list(scen_loader.scen_internal_data['EWST2024'].keys()))\n",
    "\n",
    "# Test 2.2: Validation of common columns\n",
    "print(\"\\nTest 2.2: Checking common columns\")\n",
    "common_cols = set(scen_loader.internal_data.columns) & set(scen_loader.scen_internal_data['EWST2024']['Base'].columns)\n",
    "print(\"Common columns between internal data and scenarios:\", common_cols)\n",
    "\n",
    "# Test 2.3: Test column consistency validation\n",
    "print(\"\\nTest 2.3: Testing column consistency validation\")\n",
    "try:\n",
    "    # Create inconsistent scenario data\n",
    "    inconsistent_scenarios = {\n",
    "        'Base': scenario_sets['EWST2024']['Base'],\n",
    "        'Adverse': scenario_sets['EWST2024']['Adverse'].drop(columns=['New_var1'])  # Remove one column\n",
    "    }\n",
    "    scen_loader.load_scens(source=inconsistent_scenarios, set_name='Test')\n",
    "    print(\"Warning: Inconsistent columns were accepted!\")\n",
    "except ValueError as e:\n",
    "    print(\"Successfully caught inconsistent columns error:\", str(e))\n",
    "\n",
    "# Clean up\n",
    "os.remove(excel_path)\n",
    "print(\"\\nTest file cleaned up\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Scenario Handling Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of EWST2024 Base scenario:\n",
      "            Fixed_balance   VR_balance    New_var1    New_var2\n",
      "2023-01-31    2047.924279  1660.643292  114.507924  195.406529\n",
      "2023-02-28    1833.421146  1475.749255  105.604250  198.906914\n",
      "2023-03-31    2057.460869  1419.838195  109.708775  194.978962\n",
      "2023-04-30    2089.354231  1609.263986  110.625729  180.223019\n",
      "2023-05-31    2020.098910  1654.033750  105.403965  181.899136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create synthetic scenario data\n",
    "dates = pd.date_range(start='2023-01-01', end='2025-12-31', freq='M')\n",
    "\n",
    "# Function to create scenario data with some randomness\n",
    "def create_scenario_data(base_values, scenario_factor):\n",
    "    data = {}\n",
    "    for col, base in base_values.items():\n",
    "        # Add some random variation and trend based on scenario\n",
    "        noise = np.random.normal(0, 0.1, len(dates))\n",
    "        trend = np.linspace(0, scenario_factor, len(dates))\n",
    "        values = base * (1 + noise + trend)\n",
    "        data[col] = values\n",
    "    return pd.DataFrame(data, index=dates)\n",
    "\n",
    "# Base values for variables (ensure some overlap with internal data)\n",
    "base_values = {\n",
    "    'Fixed_balance': 2000,\n",
    "    'VR_balance': 1500,\n",
    "    'New_var1': 100,  # New variable not in internal data\n",
    "    'New_var2': 200   # New variable not in internal data\n",
    "}\n",
    "\n",
    "# Create two scenario sets\n",
    "scenario_sets = {\n",
    "    'EWST2024': {\n",
    "        'Base': create_scenario_data(base_values, 0.1),\n",
    "        'Adverse': create_scenario_data(base_values, -0.2),\n",
    "        'Severe': create_scenario_data(base_values, -0.4)\n",
    "    },\n",
    "    'EWST2025': {\n",
    "        'Base': create_scenario_data(base_values, 0.15),\n",
    "        'Adverse': create_scenario_data(base_values, -0.25)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print sample of the scenario data\n",
    "print(\"Sample of EWST2024 Base scenario:\")\n",
    "print(scenario_sets['EWST2024']['Base'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2.1: Loading scenarios from Excel\n",
      "\n",
      "Scenarios loaded from Excel: ['Base', 'Adverse', 'Severe']\n",
      "\n",
      "Test 2.2: Checking common columns\n",
      "Common columns between internal data and scenarios: {'Fixed_balance', 'VR_balance'}\n",
      "\n",
      "Test 2.3: Testing column consistency validation\n",
      "Successfully caught inconsistent columns error: All scenarios in set 'Test' must have the same columns\n",
      "\n",
      "Test file cleaned up\n"
     ]
    }
   ],
   "source": [
    "# First save scenario data to Excel for testing\n",
    "import os\n",
    "\n",
    "# Create a temporary Excel file with scenarios\n",
    "excel_path = 'test_scenarios.xlsx'\n",
    "with pd.ExcelWriter(excel_path) as writer:\n",
    "    # Save EWST2024 scenarios\n",
    "    for scen_name, df in scenario_sets['EWST2024'].items():\n",
    "        df.to_excel(writer, sheet_name=scen_name, index_label='Date')\n",
    "\n",
    "# Test 2.1: Load scenarios from Excel\n",
    "print(\"Test 2.1: Loading scenarios from Excel\")\n",
    "scen_loader = tc.PPNRInternalLoader(freq='M')\n",
    "\n",
    "# Load the base internal data first\n",
    "scen_loader.load(\n",
    "    source='fake_internal.xlsx',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "# Define mapping between Excel sheet names and scenario names\n",
    "scenario_mapping = {\n",
    "    'Base': 'Base',\n",
    "    'Adverse': 'Adverse',\n",
    "    'Severe': 'Severe'\n",
    "}\n",
    "\n",
    "scen_loader.load_scens(\n",
    "    source=excel_path,\n",
    "    scens=scenario_mapping,  # Specify the mapping between sheet names and scenario names\n",
    "    set_name='EWST2024',\n",
    "    date_col='Date'\n",
    ")\n",
    "\n",
    "print(\"\\nScenarios loaded from Excel:\", list(scen_loader.scen_internal_data['EWST2024'].keys()))\n",
    "\n",
    "# Test 2.2: Validation of common columns\n",
    "print(\"\\nTest 2.2: Checking common columns\")\n",
    "common_cols = set(scen_loader.internal_data.columns) & set(scen_loader.scen_internal_data['EWST2024']['Base'].columns)\n",
    "print(\"Common columns between internal data and scenarios:\", common_cols)\n",
    "\n",
    "# Test 2.3: Test column consistency validation\n",
    "print(\"\\nTest 2.3: Testing column consistency validation\")\n",
    "try:\n",
    "    # Create inconsistent scenario data\n",
    "    inconsistent_scenarios = {\n",
    "        'Base': scenario_sets['EWST2024']['Base'],\n",
    "        'Adverse': scenario_sets['EWST2024']['Adverse'].drop(columns=['New_var1'])  # Remove one column\n",
    "    }\n",
    "    scen_loader.load_scens(source=inconsistent_scenarios, set_name='Test')\n",
    "    print(\"Warning: Inconsistent columns were accepted!\")\n",
    "except ValueError as e:\n",
    "    print(\"Successfully caught inconsistent columns error:\", str(e))\n",
    "\n",
    "# Clean up\n",
    "os.remove(excel_path)\n",
    "print(\"\\nTest file cleaned up\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### Summary of Scenario Handling Tests\n",
    "\n",
    "The tests above verify the following functionality:\n",
    "\n",
    "1. Scenario Data Loading\n",
    "   - Loading multiple scenario sets from dictionary\n",
    "   - Loading single scenario set from dictionary\n",
    "   - Loading scenarios from Excel file\n",
    "   \n",
    "2. Data Structure Validation\n",
    "   - Consistent columns across scenarios in a set\n",
    "   - Common columns between internal data and scenarios\n",
    "   - Proper error handling for inconsistent data\n",
    "\n",
    "3. Data Management\n",
    "   - Proper scenario set organization\n",
    "   - Scenario cleaning functionality\n",
    "   - Excel file handling and cleanup\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
